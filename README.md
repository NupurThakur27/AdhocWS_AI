# AdhocWS_AI
2 day Hands-on Workshop by Ashu Sir on AI
Data Visualization
Data Scrapping
# Data Visualization using Matlpotlib
xlabel(),ylabel(),bar(),scatter(),plot(),pie(),legend(),show(),grid()
Average Data generated by Facebook: 15 PB/day
Where to store this large data?
-> Bigdata hadoop

Data Scraping or API
API is for authantication scraping.

WEB SCRAPING: We can use RPA tool,Java,GoLang,Python etc.
# Web Scraping using Python:
--> BeautifulSoup
1. Visit URL (from urllib import request; <var>=request.urlopen()) 2.Download Data(<var>.read()) 3. Then Scrap the required info.
  
  HTML Parser is a collection of html tags that can scrap data from particular tag like h1, head etc.
  Cleaning is an important part of Web Scraping. Cleaning is done using Regular Expression(RE) or NLP.
  Data Summarization require a very clean data.
 # Data Cleaning using RE
 re.sub(r'\[0-9]*\]','',data)
 https://www.debuggex.com/cheatsheet/regex/python
 # Deep Learning using Python
 Machine Learning --> Predict and Classification
 Meaning of Deep Learning is to do deep analysis about data, data can be text,image,SQL dta etc.
 
 ----------------------------------------------------------------------------------------------------------------------------
 
 Library/Modules: Tensorflow (It is designed in C++), Pytorch, Keras
 
 TEXT PROCESSING: NLP Processing Tool in PYthon: NLTK, Spacy,Textblob etc.
 NLP(Processing) --> NLG(Generation) -> NLU(Understanding)
 
 ----------------------------------------------------------------------------------------------------------------------------
 # NLP
 e.g. Large amount of text data stored in any format(csv, txt, sql etc.) but it's all monotonous wihtout any subdivision then it's a tidious task to understand. Just like in Books we have chapters for better understanding.
 So to solve such problem we can divide big data to sentences(**Sentence Tokenization**) and may be for more simplifications to words(**Word Tokenization**) and then analyse them. This whole work is included in **NLP**. 
 
 **Sentiment Analysis**
 Opinion 
 Saying
 e.g. Let's consider a movie review: "Story was good but ending was not fine."
 Text -> Sentences -> words -> CSV -> Scores (0.1,0.2,0.3 ...) -> 3 opinions: Positive, Negative, Neutral
 
 Two methods for Sentiment Analysis:
 1. Raw Method
 2. Automatic Method (using Textblob)
 
 Polarity of Sentiments lie between -1 to 1 in case of TextBlob.
 Values less than 0 are negative.
 Values greater than 0 are positive.
 
 ----------------------------------------------------------------------------------------------------------------------------
 # API Access
 e.g. Twitter
 Code -> Endpoint(First Auth.)known as Customer Keys  -> Key Auth. Access Ky -> Can access Twitter Storage
 
